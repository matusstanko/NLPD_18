{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'entity': 'MISC', 'score': 0.99866974, 'index': 4, 'word': 'Ä Americans', 'start': 14, 'end': 23}]\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('output_train.csv')\n",
    "df['A_raw_entities'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_A_entities(text, raw_entities):\n",
    "    import ast\n",
    "    try:\n",
    "        entities = ast.literal_eval(raw_entities)\n",
    "    except:\n",
    "        return text\n",
    "    \n",
    "    # sort by start index to avoid messing up positions as we insert\n",
    "    entities = sorted(entities, key=lambda x: x['start'])\n",
    "    \n",
    "    offset = 0\n",
    "    for ent in entities:\n",
    "        label = ent.get('entity')\n",
    "        start = ent.get('start')\n",
    "        end = ent.get('end')\n",
    "        if start is None or end is None or not label:\n",
    "            continue\n",
    "        \n",
    "        start += offset\n",
    "        end += offset\n",
    "        start_tag = f\"<{label}>\"\n",
    "        end_tag = f\"</{label}>\"\n",
    "        text = text[:start] + start_tag + text[start:end] + end_tag + text[end:]\n",
    "        offset += len(start_tag) + len(end_tag)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def tag_B_entities(text, raw_entities):\n",
    "    import ast\n",
    "    try:\n",
    "        entities = ast.literal_eval(raw_entities)\n",
    "    except:\n",
    "        return text\n",
    "    \n",
    "    tagged = text\n",
    "    offset = 0\n",
    "\n",
    "    for ent in entities:\n",
    "        word = ent.get('word')\n",
    "        label = ent.get('entity')\n",
    "        if not word or not label:\n",
    "            continue\n",
    "\n",
    "        start = tagged.find(word, offset)\n",
    "        if start == -1:\n",
    "            continue\n",
    "\n",
    "        end = start + len(word)\n",
    "        start_tag = f\"<{label}>\"\n",
    "        end_tag = f\"</{label}>\"\n",
    "        tagged = tagged[:start] + start_tag + word + end_tag + tagged[end:]\n",
    "        offset = end + len(start_tag) + len(end_tag)\n",
    "\n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A_tagged'] = df.apply(lambda row: tag_A_entities(row['statement'], row['A_raw_entities']), axis=1)\n",
    "df['B_tagged'] = df.apply(lambda row: tag_B_entities(row['statement'], row['B_raw_entities']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           statement  label  label_binary  \\\n",
      "0  90 percent of Americans \"support universal bac...      5             1   \n",
      "1  Last year was one of the deadliest years ever ...      1             0   \n",
      "2  Bernie Sanders's plan is \"to raise your taxes ...      0             0   \n",
      "3  Voter ID is supported by an overwhelming major...      4             1   \n",
      "4  Says Barack Obama \"robbed Medicare (of) $716 b...      2             0   \n",
      "\n",
      "                                      A_raw_entities  \\\n",
      "0  [{'entity': 'MISC', 'score': 0.99866974, 'inde...   \n",
      "1                                                 []   \n",
      "2  [{'entity': 'PER', 'score': 0.9983652, 'index'...   \n",
      "3  [{'entity': 'MISC', 'score': 0.9153446, 'index...   \n",
      "4  [{'entity': 'PER', 'score': 0.9980445, 'index'...   \n",
      "\n",
      "                                      B_raw_entities  \\\n",
      "0  [{'word': '90 percent', 'entity': 'PERCENT'}, ...   \n",
      "1  [{'word': 'Last year', 'entity': 'DATE'}, {'wo...   \n",
      "2  [{'word': \"Bernie Sanders's\", 'entity': 'PERSO...   \n",
      "3               [{'word': 'NYers', 'entity': 'ORG'}]   \n",
      "4  [{'word': 'Barack Obama', 'entity': 'PERSON'},...   \n",
      "\n",
      "                                            A_tagged  \\\n",
      "0  90 percent of <MISC>Americans</MISC> \"support ...   \n",
      "1  Last year was one of the deadliest years ever ...   \n",
      "2  <PER>Bernie</PER> <PER>Sanders</PER>'s plan is...   \n",
      "3  Voter ID is supported by an overwhelming major...   \n",
      "4  Says <PER>Barack</PER> <PER>Obama</PER> \"robbe...   \n",
      "\n",
      "                                            B_tagged  \n",
      "0  <PERCENT>90 percent</PERCENT> of <NORP>America...  \n",
      "1  <DATE>Last year</DATE> was <CARDINAL>one</CARD...  \n",
      "2  <PERSON>Bernie Sanders's</PERSON> plan is \"to ...  \n",
      "3  Voter ID is supported by an overwhelming major...  \n",
      "4  Says <PERSON>Barack Obama</PERSON> \"robbed <OR...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "df.to_csv('AB_tagged_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[PER_]', '[/PER_]', '[MISC_]', '[/MISC_]', '[LOC_]', '[/LOC_]', '[ORG_]', '[/ORG_]']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "entity_labels = set()\n",
    "\n",
    "for row in df['A_raw_entities']:\n",
    "    try:\n",
    "        entities = ast.literal_eval(row)\n",
    "    except:\n",
    "        continue\n",
    "    for ent in entities:\n",
    "        label = ent.get('entity')\n",
    "        if label:\n",
    "            entity_labels.add(label)\n",
    "\n",
    "# now create special tokens\n",
    "special_tokens = []\n",
    "for label in entity_labels:\n",
    "    special_tokens.append(f\"[{label}_]\")\n",
    "    special_tokens.append(f\"[/{label}_]\")\n",
    "\n",
    "print(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
