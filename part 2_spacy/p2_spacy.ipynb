{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edc719f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "import ast\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from spacy.training import Example\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55156ac7",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ca875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"output_train.csv\")\n",
    "df_valid = pd.read_csv(\"output_valid.csv\")\n",
    "df_test  = pd.read_csv(\"output_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20966c2",
   "metadata": {},
   "source": [
    "## XML Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b90b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_offsets(text, entities): # adds start and end pos.\n",
    "    if not isinstance(entities, list):\n",
    "        return []\n",
    "    used, results = [False] * len(text), []\n",
    "    for ent in entities:\n",
    "        word = ent.get(\"word\")\n",
    "        label = ent.get(\"entity\", \"\").lower()\n",
    "        if not word or not label: # skip empty\n",
    "            continue\n",
    "        # finds the word in text and notes s/e\n",
    "        m = re.search(re.escape(word), text, re.IGNORECASE)\n",
    "        if m and not any(used[m.start():m.end()]):\n",
    "            results.append({\"start\": m.start(), \"end\": m.end(), \"entity\": label})\n",
    "            for i in range(m.start(), m.end()):\n",
    "                used[i] = True\n",
    "    return results\n",
    "\n",
    "def merge_adjacent_entities(ents): # merge if same label\n",
    "    if not ents:\n",
    "        return []\n",
    "    ents = sorted(ents, key=lambda x: x[\"start\"]) # sort so left to right\n",
    "    merged = [ents[0]] # leftmost entity\n",
    "    for curr in ents[1:]: # the rest\n",
    "        last = merged[-1]\n",
    "        if curr[\"entity\"] == last[\"entity\"] and curr[\"start\"] <= last[\"end\"] + 1:\n",
    "                # same label & touching\n",
    "            last[\"end\"] = curr[\"end\"]\n",
    "        else:\n",
    "            merged.append(curr)\n",
    "    return merged\n",
    "\n",
    "def insert_xml_tags(text, entities): # put entity tags into text\n",
    "    if isinstance(entities, str):\n",
    "        try:\n",
    "            entities = ast.literal_eval(entities)\n",
    "        except:\n",
    "            return text\n",
    "    spans = add_offsets(text, entities)\n",
    "    if not spans:\n",
    "        return text\n",
    "    merged = merge_adjacent_entities(spans) # merge adjacent\n",
    "    offset = 0\n",
    "    # insert <entity tags>\n",
    "    for ent in sorted(merged, key=lambda x: x[\"start\"]):\n",
    "        o_tag, c_tag = f\"<{ent['entity']}>\", f\"</{ent['entity']}>\"\n",
    "        s, e = ent[\"start\"] + offset, ent[\"end\"] + offset\n",
    "        text = text[:s] + o_tag + text[s:e] + c_tag + text[e:]\n",
    "        offset += len(o_tag) + len(c_tag)\n",
    "    return text\n",
    "\n",
    "# apply to all splits\n",
    "for df in (df_train, df_valid, df_test):\n",
    "    df[\"B_XML_statement\"] = df.apply(lambda r: insert_xml_tags(r[\"statement\"], r[\"B_raw_entities\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d38e25",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8cbbf8",
   "metadata": {},
   "source": [
    "## Preparing data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b6c1fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_data(df, label_col): # prepares data for SpaCy training\n",
    "    texts = df[\"B_XML_statement\"].tolist()\n",
    "    labels = df[label_col].tolist()\n",
    "    cats = [{\"cats\": {\"1\": bool(l), \"0\": not bool(l)}} for l in labels]\n",
    "    return list(zip(texts, cats)), texts, labels\n",
    "\n",
    "train_data, _, _= make_data(df_train, \"label_binary\")\n",
    "valid_data, valid_texts, valid_labels = make_data(df_valid, \"label_binary\")\n",
    "test_data, test_texts, test_labels = make_data(df_test, \"label_binary\")\n",
    "\n",
    "# build spacy model with BOW classifier\n",
    "nlp = spacy.blank(\"en\")\n",
    "textcat = nlp.add_pipe(\n",
    "    \"textcat\",\n",
    "    last=True,\n",
    "    config={\"model\": {\n",
    "            \"@architectures\": \"spacy.TextCatBOW.v3\",\n",
    "            \"exclusive_classes\": True,\n",
    "            \"ngram_size\": 1,\n",
    "            \"no_output_layer\": False}})\n",
    "# add classification labels\n",
    "textcat.add_label(\"0\")\n",
    "textcat.add_label(\"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee68f42",
   "metadata": {},
   "source": [
    "## Model Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a35c401c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 — Train Loss: 475.3697 — Val F1: 64.6231%\n",
      "Epoch 2/10 — Train Loss: 368.6566 — Val F1: 59.3663%\n",
      "Epoch 3/10 — Train Loss: 308.3186 — Val F1: 58.6507%\n",
      "Epoch 4/10 — Train Loss: 270.1716 — Val F1: 60.5051%\n",
      "Epoch 5/10 — Train Loss: 241.5426 — Val F1: 61.2855%\n",
      "Epoch 6/10 — Train Loss: 220.2562 — Val F1: 61.1845%\n",
      "Epoch 7/10 — Train Loss: 203.6183 — Val F1: 61.8235%\n",
      "Epoch 8/10 — Train Loss: 189.4576 — Val F1: 57.3753%\n",
      "Epoch 9/10 — Train Loss: 176.9292 — Val F1: 57.4882%\n",
      "Epoch 10/10 — Train Loss: 166.6377 — Val F1: 59.8790%\n",
      "Test scores: {'accuracy': '65.90%', 'f1': '59.32%', 'precision': '59.98%', 'recall': '58.68%'}\n"
     ]
    }
   ],
   "source": [
    "n_iter = 10\n",
    "train_losses = []\n",
    "val_f1s = []\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "for epoch in range(n_iter):\n",
    "    random.shuffle(train_data)\n",
    "    losses = {}\n",
    "    # training\n",
    "    for batch in spacy.util.minibatch(train_data, size=8):\n",
    "        examples = []\n",
    "        for text, ann in batch:\n",
    "            doc = nlp.make_doc(text)\n",
    "            examples.append(Example.from_dict(doc, ann))\n",
    "        nlp.update(examples, drop=0.2, sgd=optimizer, losses=losses)\n",
    "    train_losses.append(losses[\"textcat\"])\n",
    "\n",
    "    # validation eval\n",
    "    preds = [nlp(txt).cats for txt in valid_texts]\n",
    "    pred_bin = [int(p[\"1\"] >= 0.5) for p in preds]\n",
    "    f1 = f1_score(valid_labels, pred_bin)*100\n",
    "    val_f1s.append(f1)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{n_iter} — \"\n",
    "        f\"Train Loss: {losses['textcat']:.4f} — \"\n",
    "        f\"Val F1: {f1:.4f}%\")\n",
    "\n",
    "# test evaluation\n",
    "test_preds= [nlp(t).cats for t in test_texts]\n",
    "test_bin = [int(p[\"1\"] >= 0.5) for p in test_preds]\n",
    "scores = {\n",
    "    \"accuracy\": accuracy_score(test_labels, test_bin)*100,\n",
    "    \"f1\": f1_score(test_labels, test_bin)*100,\n",
    "    \"precision\": precision_score(test_labels, test_bin)*100,\n",
    "    \"recall\": recall_score(test_labels, test_bin)*100\n",
    "}\n",
    "print(\"Test scores:\", {k: f\"{v:.2f}%\" for k,v in scores.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4023877b",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be45275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training + Validation curve\n",
    "plt.figure()\n",
    "plt.plot(range(1, n_iter+1), train_losses, marker=\"o\", label=\"Train Loss\")\n",
    "plt.plot(range(1, n_iter+1), val_f1s,      marker=\"s\", linestyle=\"--\", label=\"Val F1\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Training Loss & Validation F1\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"spacy_xml_training_validation_curve.png\")\n",
    "plt.close()\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_bin)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=[\"0\",\"1\"])\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix_spacy_xml.png\")\n",
    "plt.close()\n",
    "\n",
    "# ROC curve\n",
    "probs      = [p[\"1\"] for p in test_preds]\n",
    "fpr, tpr, _ = roc_curve(test_labels, probs)\n",
    "roc_auc    = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "plt.plot([0,1], [0,1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"roc_curve_spacy_xml.png\")\n",
    "plt.close()\n",
    "\n",
    "# Save results\n",
    "pd.DataFrame([scores]).to_csv(\"spacy_with_xml_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
