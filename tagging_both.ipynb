{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'entity': 'MISC', 'score': 0.99962676, 'index': 22, 'word': 'Ä CO', 'start': 108, 'end': 110}, {'entity': 'MISC', 'score': 0.9995419, 'index': 23, 'word': 'VID', 'start': 110, 'end': 113}, {'entity': 'MISC', 'score': 0.998911, 'index': 24, 'word': '-', 'start': 113, 'end': 114}, {'entity': 'MISC', 'score': 0.99878925, 'index': 25, 'word': '19', 'start': 114, 'end': 116}]\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('output_test.csv')\n",
    "df['A_raw_entities'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_A_entities(text, raw_entities):\n",
    "    import ast\n",
    "    try:\n",
    "        entities = ast.literal_eval(raw_entities)\n",
    "    except:\n",
    "        return text\n",
    "    \n",
    "    # sort by start index to avoid messing up positions as we insert\n",
    "    entities = sorted(entities, key=lambda x: x['start'])\n",
    "    \n",
    "    offset = 0\n",
    "    for ent in entities:\n",
    "        label = ent.get('entity')\n",
    "        start = ent.get('start')\n",
    "        end = ent.get('end')\n",
    "        if start is None or end is None or not label:\n",
    "            continue\n",
    "        \n",
    "        start += offset\n",
    "        end += offset\n",
    "        start_tag = f\"[{label}]\"\n",
    "        end_tag = f\"[/{label}]\"\n",
    "        text = text[:start] + start_tag + text[start:end] + end_tag + text[end:]\n",
    "        offset += len(start_tag) + len(end_tag)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def tag_B_entities(text, raw_entities):\n",
    "    import ast\n",
    "    try:\n",
    "        entities = ast.literal_eval(raw_entities)\n",
    "    except:\n",
    "        return text\n",
    "    \n",
    "    tagged = text\n",
    "    offset = 0\n",
    "\n",
    "    for ent in entities:\n",
    "        word = ent.get('word')\n",
    "        label = ent.get('entity')\n",
    "        if not word or not label:\n",
    "            continue\n",
    "\n",
    "        start = tagged.find(word, offset)\n",
    "        if start == -1:\n",
    "            continue\n",
    "\n",
    "        end = start + len(word)\n",
    "        start_tag = f\"[{label}]\"\n",
    "        end_tag = f\"[/{label}]\"\n",
    "        tagged = tagged[:start] + start_tag + word + end_tag + tagged[end:]\n",
    "        offset = end + len(start_tag) + len(end_tag)\n",
    "\n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A_tagged'] = df.apply(lambda row: tag_A_entities(row['statement'], row['A_raw_entities']), axis=1)\n",
    "df['B_tagged'] = df.apply(lambda row: tag_B_entities(row['statement'], row['B_raw_entities']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           statement  label  label_binary  \\\n",
      "0  Three doctors from the same hospital 'die sudd...      1             0   \n",
      "1                      Say Joe Biden is a pedophile.      0             0   \n",
      "2  A photo shows President Joe Biden and Ukrainia...      1             0   \n",
      "3  It will cost $50,000 per enrollee in Obamacare...      1             0   \n",
      "4  The Federal Register - which houses all Washin...      3             1   \n",
      "\n",
      "                                      A_raw_entities  \\\n",
      "0  [{'entity': 'MISC', 'score': 0.99962676, 'inde...   \n",
      "1  [{'entity': 'PER', 'score': 0.9993856, 'index'...   \n",
      "2  [{'entity': 'PER', 'score': 0.9996147, 'index'...   \n",
      "3  [{'entity': 'MISC', 'score': 0.99520916, 'inde...   \n",
      "4  [{'entity': 'ORG', 'score': 0.6887246, 'index'...   \n",
      "\n",
      "                                      B_raw_entities  \\\n",
      "0  [{'word': 'Three', 'entity': 'CARDINAL'}, {'wo...   \n",
      "1        [{'word': 'Joe Biden', 'entity': 'PERSON'}]   \n",
      "2  [{'word': 'Joe Biden', 'entity': 'PERSON'}, {'...   \n",
      "3  [{'word': '50,000', 'entity': 'MONEY'}, {'word...   \n",
      "4  [{'word': 'The Federal Register - which', 'ent...   \n",
      "\n",
      "                                            A_tagged  \\\n",
      "0  Three doctors from the same hospital 'die sudd...   \n",
      "1  Say [PER]Joe[/PER] [PER]Biden[/PER] is a pedop...   \n",
      "2  A photo shows President [PER]Joe[/PER] [PER]Bi...   \n",
      "3  It will cost $50,000 per enrollee in [MISC]Oba...   \n",
      "4  The [ORG]Federal[/ORG] [ORG]Register[/ORG] - w...   \n",
      "\n",
      "                                            B_tagged  \n",
      "0  [CARDINAL]Three[/CARDINAL] doctors from the sa...  \n",
      "1     Say [PERSON]Joe Biden[/PERSON] is a pedophile.  \n",
      "2  A photo shows President [PERSON]Joe Biden[/PER...  \n",
      "3  It will cost $[MONEY]50,000[/MONEY] per enroll...  \n",
      "4  [ORG]The Federal Register - which[/ORG] houses...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "df.to_csv('AB_tagged_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[PER_]', '[/PER_]', '[MISC_]', '[/MISC_]', '[LOC_]', '[/LOC_]', '[ORG_]', '[/ORG_]']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "entity_labels = set()\n",
    "\n",
    "for row in df['A_raw_entities']:\n",
    "    try:\n",
    "        entities = ast.literal_eval(row)\n",
    "    except:\n",
    "        continue\n",
    "    for ent in entities:\n",
    "        label = ent.get('entity')\n",
    "        if label:\n",
    "            entity_labels.add(label)\n",
    "\n",
    "# now create special tokens\n",
    "special_tokens = []\n",
    "for label in entity_labels:\n",
    "    special_tokens.append(f\"[{label}_]\")\n",
    "    special_tokens.append(f\"[/{label}_]\")\n",
    "\n",
    "print(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
