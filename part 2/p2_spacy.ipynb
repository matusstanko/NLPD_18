{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b90b7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 â€” Train Loss: 475.7278 â€” Val F1: 60.5856%\n",
      "Epoch 2/10 â€” Train Loss: 367.9199 â€” Val F1: 62.7451%\n",
      "Epoch 3/10 â€” Train Loss: 309.5594 â€” Val F1: 60.1175%\n",
      "Epoch 4/10 â€” Train Loss: 269.9840 â€” Val F1: 61.7357%\n",
      "Epoch 5/10 â€” Train Loss: 241.7007 â€” Val F1: 58.7856%\n",
      "Epoch 6/10 â€” Train Loss: 219.1602 â€” Val F1: 61.0338%\n",
      "Epoch 7/10 â€” Train Loss: 203.6863 â€” Val F1: 59.9696%\n",
      "Epoch 8/10 â€” Train Loss: 189.2522 â€” Val F1: 58.6722%\n",
      "Epoch 9/10 â€” Train Loss: 176.6376 â€” Val F1: 58.2474%\n",
      "Epoch 10/10 â€” Train Loss: 166.5384 â€” Val F1: 58.5139%\n",
      "ðŸ“Š Test scores: {'accuracy': 66.59407665505228, 'f1': 58.96201177100053, 'precision': 61.49553571428571, 'recall': 56.62898252826311}\n",
      "âœ… DONE â€” all SpaCy XML tagging + metrics saved.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "import ast\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from spacy.training import Example\n",
    "\n",
    "random.seed = 42\n",
    "\n",
    "# ========== 1. Load data ==========\n",
    "df_train = pd.read_csv(\"output_train.csv\")\n",
    "df_valid = pd.read_csv(\"output_valid.csv\")\n",
    "df_test  = pd.read_csv(\"output_test.csv\")\n",
    "# ========== 2. XML tagging utils ==========\n",
    "def add_offsets(text, entities):\n",
    "    if not isinstance(entities, list):\n",
    "        return []\n",
    "    used, results = [False] * len(text), []\n",
    "    for ent in entities:\n",
    "        word = ent.get(\"word\")\n",
    "        label = ent.get(\"entity\", \"\").lower()\n",
    "        if not word or not label:\n",
    "            continue\n",
    "        m = re.search(re.escape(word), text, re.IGNORECASE)\n",
    "        if m and not any(used[m.start():m.end()]):\n",
    "            results.append({\"start\": m.start(), \"end\": m.end(), \"entity\": label})\n",
    "            for i in range(m.start(), m.end()):\n",
    "                used[i] = True\n",
    "    return results\n",
    "\n",
    "def merge_adjacent_entities(ents):\n",
    "    if not ents:\n",
    "        return []\n",
    "    ents = sorted(ents, key=lambda x: x[\"start\"])\n",
    "    merged = [ents[0]]\n",
    "    for curr in ents[1:]:\n",
    "        last = merged[-1]\n",
    "        if curr[\"entity\"] == last[\"entity\"] and curr[\"start\"] <= last[\"end\"] + 1:\n",
    "            last[\"end\"] = curr[\"end\"]\n",
    "        else:\n",
    "            merged.append(curr)\n",
    "    return merged\n",
    "\n",
    "def insert_xml_tags(text, entities):\n",
    "    if isinstance(entities, str):\n",
    "        try:\n",
    "            entities = ast.literal_eval(entities)\n",
    "        except:\n",
    "            return text\n",
    "    spans = add_offsets(text, entities)\n",
    "    if not spans:\n",
    "        return text\n",
    "    merged = merge_adjacent_entities(spans)\n",
    "    offset = 0\n",
    "    for ent in sorted(merged, key=lambda x: x[\"start\"]):\n",
    "        o_tag, c_tag = f\"<{ent['entity']}>\", f\"</{ent['entity']}>\"\n",
    "        s, e = ent[\"start\"] + offset, ent[\"end\"] + offset\n",
    "        text = text[:s] + o_tag + text[s:e] + c_tag + text[e:]\n",
    "        offset += len(o_tag) + len(c_tag)\n",
    "    return text\n",
    "\n",
    "# apply to all splits\n",
    "for df in (df_train, df_valid, df_test):\n",
    "    df[\"B_XML_statement\"] = df.apply(\n",
    "        lambda r: insert_xml_tags(r[\"statement\"], r[\"B_raw_entities\"]),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# ========== 3. Prepare data ==========\n",
    "def make_data(df, label_col):\n",
    "    texts  = df[\"B_XML_statement\"].tolist()\n",
    "    labels = df[label_col].tolist()\n",
    "    cats   = [{\"cats\": {\"1\": bool(l), \"0\": not bool(l)}} for l in labels]\n",
    "    return list(zip(texts, cats)), texts, labels\n",
    "\n",
    "train_data, _, _           = make_data(df_train, \"label_binary\")\n",
    "valid_data, valid_texts, valid_labels = make_data(df_valid, \"label_binary\")\n",
    "test_data,  test_texts,  test_labels  = make_data(df_test,  \"label_binary\")\n",
    "\n",
    "# ========== 4. Build the model ==========\n",
    "nlp = spacy.blank(\"en\")\n",
    "textcat = nlp.add_pipe(\n",
    "    \"textcat\",\n",
    "    last=True,\n",
    "    config={\n",
    "        \"model\": {\n",
    "            \"@architectures\": \"spacy.TextCatBOW.v3\",\n",
    "            \"exclusive_classes\": True,\n",
    "            \"ngram_size\": 1,\n",
    "            \"no_output_layer\": False\n",
    "        }\n",
    "    }\n",
    ")\n",
    "textcat.add_label(\"0\")\n",
    "textcat.add_label(\"1\")\n",
    "\n",
    "# ========== 5. Train w/ validation ==========\n",
    "n_iter       = 10\n",
    "train_losses = []\n",
    "val_f1s      = []\n",
    "optimizer    = nlp.begin_training()\n",
    "\n",
    "for epoch in range(n_iter):\n",
    "    random.shuffle(train_data)\n",
    "    losses = {}\n",
    "    # training\n",
    "    for batch in spacy.util.minibatch(train_data, size=8):\n",
    "        examples = []\n",
    "        for text, ann in batch:\n",
    "            doc = nlp.make_doc(text)\n",
    "            examples.append(Example.from_dict(doc, ann))\n",
    "        nlp.update(examples, drop=0.2, sgd=optimizer, losses=losses)\n",
    "    train_losses.append(losses[\"textcat\"])\n",
    "\n",
    "    # validation eval\n",
    "    preds      = [nlp(txt).cats for txt in valid_texts]\n",
    "    pred_bin   = [int(p[\"1\"] >= 0.5) for p in preds]\n",
    "    f1         = f1_score(valid_labels, pred_bin)*100\n",
    "    val_f1s.append(f1)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{n_iter} â€” \"\n",
    "        f\"Train Loss: {losses['textcat']:.4f} â€” \"\n",
    "        f\"Val F1: {f1:.4f}%\"\n",
    "    )\n",
    "\n",
    "# ========== 6. Test evaluation ==========\n",
    "test_preds = [nlp(t).cats for t in test_texts]\n",
    "test_bin   = [int(p[\"1\"] >= 0.5) for p in test_preds]\n",
    "scores     = {\n",
    "    \"accuracy\":  accuracy_score(test_labels, test_bin)*100,\n",
    "    \"f1\":        f1_score(test_labels, test_bin)*100,\n",
    "    \"precision\": precision_score(test_labels, test_bin)*100,\n",
    "    \"recall\":    recall_score(test_labels, test_bin)*100\n",
    "}\n",
    "print(\"ðŸ“Š Test scores:\", scores)\n",
    "\n",
    "# ========== 7. Plots & save ==========\n",
    "# Training + Validation curve\n",
    "plt.figure()\n",
    "plt.plot(range(1, n_iter+1), train_losses, marker=\"o\", label=\"Train Loss\")\n",
    "plt.plot(range(1, n_iter+1), val_f1s,      marker=\"s\", linestyle=\"--\", label=\"Val F1\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Training Loss & Validation F1\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"spacy_xml_training_validation_curve.png\")\n",
    "plt.close()\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_bin)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=[\"0\",\"1\"])\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix_spacy_xml.png\")\n",
    "plt.close()\n",
    "\n",
    "# ROC curve\n",
    "probs      = [p[\"1\"] for p in test_preds]\n",
    "fpr, tpr, _ = roc_curve(test_labels, probs)\n",
    "roc_auc    = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "plt.plot([0,1], [0,1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"roc_curve_spacy_xml.png\")\n",
    "plt.close()\n",
    "\n",
    "# Save results\n",
    "pd.DataFrame([scores]).to_csv(\"spacy_with_xml_results.csv\", index=False)\n",
    "print(\"âœ… DONE â€” all SpaCy XML tagging + metrics saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
